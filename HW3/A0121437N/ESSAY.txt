1. In this assignment, we didn't ask you to support phrasal queries, which is a
feature that is typically supported in web search engines. Describe how you
would support phrasal search in conjunction with the VSM model. A sketch of the
algorithm is sufficient. (For those of you who like a challenge, please go ahead
and implement this feature in your submission but clearly demarcate it in your
code and allow this feature to be turned on or off using the command line switch
"-x" (where "-x" means to turn on the extended processing of phrasal queries).
We will give a small bonus to submissions that achieve this functionality
correctly).

One method would be to index biword tokens instead of indexing single word
tokens, and then filtering out the documents that do not contain the exact
phrases if the query was more than two words long. However, this would increase
the size of the dictionary as the number of tokens would increase from N to
roughly N * N. This method is also not very efficient if the number of documents
retrieved is still large, for example if the phrasal query contains a common
biword token such as 'is the'. However, if the query were only two words long,
we would no longer need to perform the filtering step, and the query would be
performed quickly.

Another way would be to modify the indexing phase to include positional indices.
Then, during the search phase conduct 2 searches. First, searching by relevance
using the VSM model, then conducting a boolean search using the positional
indices to find documents that match the exact phrase. After which, we filter
out documents retrieved from the VSM model that do not occur in the list of
documents that match the exact phrases. This would be a more efficient strategy
than using biword indices as it would have a smaller dictionary size, it would
perform a lot faster in phrasal queries that contain more than 2 words, and
lastly it would not require any reading of documents during the querying phase,
which would greatly affect the query speed.

2. Describe how your search engine reacts to long documents and long queries as
compared to short documents and queries. Is the normalization you use sufficient
to address the problems (see Section 6.4.4 for a hint)? In your judgement, is
the ltc.lnc scheme (n.b., not the ranking scheme you were asked to implement)
sufficient for retrieving documents from the Reuters-21578 collection?

The length of a query would affect performance, since more terms would require
more reads of the postings file and also more calculations will be required to
generate cosine scores.

The length of documents would affect the 'relevance' scores of documents as
short documents with multiple occurrances of single a word in a query, could
rank higher than a long document that contains every word in the query.

For example, we take a query 'best insurance', and have 2 documents, A and B. If
A were a 2 word long document containing only 'good insurance', and B were a 100
word document containing '...best insurance...' only once in the document, the
cosine normalized term frequency of 'insurance' in A would be a lot larger than
that of the sum of the cosine normalized term frequencies of 'insurance'. This
would mean that A would be ranked higher than B.

Thus, this problem is addressed in 6.4.4 of the textbook, where we try to
increase relevance of longer documents while we decrease the relevance of
shorter ones.

The ltc.lnc scheme differs from the scheme we were asked to implement (lnc.ltc).
This scheme includes idf when weighting document terms and excludes idf when
weighting query terms. This could possibly improve the issue as uncommon terms
would now be weighted higher in documents and thus improve long documents'
relevance. But this could also improve the relevance scores of short documents,
as in the example above, if 'good' were a common term and 'insurance' an
uncommon one, the weight of 'insurance' would increase in both A and B, and
the ranking remain unchanged.

3. Do you think zone or field parametric indices would be useful for practical
search in the Reuters collection? Note: the Reuters collection does have
metadata for each article but the quality of the metadata is not uniform, nor
are the metadata classifications uniformly applied (some documents have it, some
don't). Hint: for the next Homework #4, we will be using field metadata, so if
you want to base Homework #4 on your Homework #3, you're welcomed to start
support of this early (although no extra credit will be given if it's right).

It would be useful as with such metadata, we could possibly rank documents more
accurately. For example, if a document contained a query term in its title, it
should be ranked higher than a document that contained a query term in its
references. We could weight terms found in specific zones higher than other
terms and thus improve the relevance of the searches.

It would also be useful as we can specify and narrow down searches to more
specific zones instead of focusing on the entire document, which would increase
the precision of searches. For example, without zone or field parametric
indices, if I wanted to search for documents with 'insurance' in the title, all
documents containing 'insurance' will be returned, including documents without
'insurance' in the title. With zone or field parametric indices, only documents
containing 'insurance' in the title will be returned. Since the number of
false positives decreases, the search is more precise.